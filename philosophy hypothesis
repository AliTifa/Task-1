
import requests
from bs4 import BeautifulSoup
import time


def wiki_phillaw(url):
    data = requests.get(url)
    m = data.text
    soup = BeautifulSoup(m, "html.parser")

    b = []

    for link in soup.findAll("p"):

        if link.a is not None:
          l = (link.a['href'])
          b.append('https://en.wikipedia.org' + str(l))
          break
    return b


links = wiki_phillaw('https://en.wikipedia.org/wiki/Special:Random ')
i = 1
while i > 0:
    print(str(links[0]))
    newlink = wiki_phillaw(str(links[0]))
    links = newlink
    i += 1
    time.sleep(0.5)
    if links[0] == 'https://en.wikipedia.org/wiki/Philosophy':
        print(str(links[0]))
        break


